<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="alternate" type="application/rss+xml" title="sontek&#x27;s Engineering Blog" href="/rss.xml"/><title>Running a kubernetes cluster locally with kind</title><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/59351a1314c8a8b6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/59351a1314c8a8b6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/95e79f6f6f52c645.css" as="style"/><link rel="stylesheet" href="/_next/static/css/95e79f6f6f52c645.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-d7b038a63b619762.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-2a9c662ddd7329fb.js" defer=""></script><script src="/_next/static/chunks/pages/_app-267db8380a174e21.js" defer=""></script><script src="/_next/static/chunks/996-9e3c12b77542c098.js" defer=""></script><script src="/_next/static/chunks/771-5e4a02ed896d5599.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...id%5D-426e76fedd45ec38.js" defer=""></script><script src="/_next/static/yFdG3iKkjvLWIOVsrJ3da/_buildManifest.js" defer=""></script><script src="/_next/static/yFdG3iKkjvLWIOVsrJ3da/_ssgManifest.js" defer=""></script><script src="/_next/static/yFdG3iKkjvLWIOVsrJ3da/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div><div class="grid"><div class="col"><header id="banner" class="body"><h1><a href="/">sontek.net</a></h1></header></div><div class="col menu"><nav><ul><li><a href="/">Home</a></li><li><a href="/blog">Blog</a></li><li><a href="/resume">Resume</a></li><li><a href="/about">About</a></li></ul></nav></div></div><div class="container"><article class="blog_article__NoEy4"><h1 class="util_headingXl__knZ_h">Running a kubernetes cluster locally with kind</h1><div class="util_lightText__xcqUE"><time dateTime="2023-07-20T20:00:00-04:00">July 20, 2023</time></div><div><p>Previously I <a href="/blog/2022/local_kubeadm_cluster">showed</a> how to run kubernetes
locally with <code>kubeadm</code> and VMs but sometimes that is overkill so I wanted to
show how to run <a href="https://kind.sigs.k8s.io/">kind</a> which is "kuberetes in
docker".</p>
<h1>Creating your first cluster</h1>
<p>kind is a very flexible way to run kubernetes locally and allows you to run
single node or multinode clusters while having the flexibility to use all
the features of kubernetes success as ingress.</p>
<p>To create your first cluster it is as simple as running:</p>
<pre><code class="hljs language-bash">‚ùØ kind create cluster  

Creating cluster <span class="hljs-string">"kind"</span> ...
 ‚úì Ensuring node image (kindest/node:v1.27.3) üñº 
 ‚úì Preparing nodes üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
Set kubectl context to <span class="hljs-string">"kind-kind"</span>
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/<span class="hljs-comment">#community üôÇ</span>
</code></pre>
<p>You now have a functioning kubernetes cluster and you
can view what it created:</p>
<pre><code class="hljs language-bash">‚ùØ k get node
NAME                 STATUS   ROLES           AGE     VERSION
kind-control-plane   Ready    control-plane   4m26s   v1.27.3
</code></pre>
<p>You can also verify that it is running inside docker:</p>
<pre><code class="hljs language-bash">‚ùØ docker ps
CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS         PORTS                       NAMES
1c3ba74dc29b   kindest/node:v1.27.3   <span class="hljs-string">"/usr/local/bin/entr‚Ä¶"</span>   3 minutes ago   Up 3 minutes   127.0.0.1:59327->6443/tcp   kind-control-plane
</code></pre>
<h1>Making the cluster useful</h1>
<p>There are a few things you'll notice with the command we ran originally:</p>
<ul>
<li>It grabbed the latest kubernetes version available</li>
<li>It is running a single node cluster</li>
<li>No ingress available</li>
</ul>
<p>Luckily kind makes it really easy to customize your local cluster to be what
you want it to be by using a <code>YAML</code> configuration.</p>
<p>Create the configuration:</p>
<pre><code class="hljs language-yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">Cluster</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kind.x-k8s.io/v1alpha4</span>
<span class="hljs-attr">nodes:</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">control-plane</span>
  <span class="hljs-attr">kubeadmConfigPatches:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">|
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
</span>  <span class="hljs-attr">extraPortMappings:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span>
    <span class="hljs-attr">hostPort:</span> <span class="hljs-number">80</span>
    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">443</span>
    <span class="hljs-attr">hostPort:</span> <span class="hljs-number">443</span>
    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span>
</code></pre>
<p>With this we've now generated a 4 node cluster where we have a single
control-plane and three workers.  Then we defined some extra configuration on
the control-plane:</p>
<ul>
<li><strong>kubeadmConfigPatches</strong>: We want to change the default configuration the
cluster uses so it'll tag the nodes with the <code>ingress-ready</code> label so the
controller will use them.</li>
<li><strong>extraPortMappings</strong>: allow the local host to make requests to the Ingress controller over ports 80/443</li>
<li><strong>node-labels</strong>: only allow the ingress controller to run on specific node(s) matching the label selector</li>
</ul>
<p>So now we can create the new cluster with the configuration. Save that config
as <code>kind_config.yml</code> and then run:</p>
<pre><code class="hljs language-bash">‚ùØ kind create cluster --image kindest/node:v1.25.11 --config kind_config.yml --name kind-multinode
</code></pre>
<p>This time I've added a few additional flags on the commandline. <code>--image</code>
allows us to use a different version of kubernetes and <code>--name</code> allows us to
make more than one cluster. So if you didn't destroy the first cluster you'll
see we have two of them now:</p>
<pre><code class="hljs language-bash">‚ùØ kind get clusters
kind
kind-multinode
</code></pre>
<p>but <code>kind</code> will swap the to the newest cluster by default:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl config current-context
kind-kind-multinode

‚ùØ kubectl get node
NAME                           STATUS   ROLES           AGE    VERSION
kind-multinode-control-plane   Ready    control-plane   107s   v1.25.11
kind-multinode-worker          Ready    &#x3C;none>          88s    v1.25.11
kind-multinode-worker2         Ready    &#x3C;none>          88s    v1.25.11
kind-multinode-worker3         Ready    &#x3C;none>          88s    v1.25.11
</code></pre>
<p>Now we need to get the <code>ingress-nginx</code> controller installed so we can start
using our cluster with ingress:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml
</code></pre>
<p>The manifests contains <code>kind</code> specific patches to forward the hostPorts to the ingress controller, set taint tolerations and schedule it to the custom labelled node.</p>
<p>This will take a little bit of time to get up and running, you can monitor it
by running:</p>
<pre><code class="hljs language-bash">kubectl <span class="hljs-built_in">wait</span> --namespace ingress-nginx \
  --<span class="hljs-keyword">for</span>=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --<span class="hljs-built_in">timeout</span>=90s
</code></pre>
<p>or just manually check the status:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl get all -n ingress-nginx
NAME                                            READY   STATUS              RESTARTS   AGE
pod/ingress-nginx-admission-create-bbmlc        0/1     Completed           0          68s
pod/ingress-nginx-admission-patch-qlnr8         0/1     Completed           2          68s
pod/ingress-nginx-controller-5f748f78c8-6tc6b   0/1     ContainerCreating   0          68s

NAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/ingress-nginx-controller             NodePort    10.96.228.248   &#x3C;none>        80:31771/TCP,443:31759/TCP   68s
service/ingress-nginx-controller-admission   ClusterIP   10.96.180.126   &#x3C;none>        443/TCP                      68s

NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-nginx-controller   0/1     1            0           68s

NAME                                                  DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-nginx-controller-5f748f78c8   1         1         0       68s

NAME                                       COMPLETIONS   DURATION   AGE
job.batch/ingress-nginx-admission-create   1/1           22s        68s
job.batch/ingress-nginx-admission-patch    1/1           35s        68s
</code></pre>
<p>Once <code>ingress-nginx-controller</code> is in <code>Running</code> state you are read to go!</p>
<h1>Deploying your first app</h1>
<p>To prove that the cluster is working correctly we will deploy
<a href="https://github.com/Kong/httpbin">httpbin</a> which is a nice little API server
so we can prove everything is working.</p>
<p>Create a <code>httbin.yml</code> file and paste this into it:</p>
<pre><code class="hljs language-yaml"><span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">httpbin</span>
    <span class="hljs-attr">service:</span> <span class="hljs-string">httpbin</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">ports:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span>
    <span class="hljs-attr">port:</span> <span class="hljs-number">8000</span>
    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">8080</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">httpbin</span>
<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">replicas:</span> <span class="hljs-number">2</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">matchLabels:</span>
      <span class="hljs-attr">app:</span> <span class="hljs-string">httpbin</span>
      <span class="hljs-attr">version:</span> <span class="hljs-string">v1</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">metadata:</span>
      <span class="hljs-attr">labels:</span>
        <span class="hljs-attr">app:</span> <span class="hljs-string">httpbin</span>
        <span class="hljs-attr">version:</span> <span class="hljs-string">v1</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/mccutchen/go-httpbin</span>
        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin</span>
        <span class="hljs-attr">ports:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8080</span>
</code></pre>
<p>This is creating a couple of Kubernetes resources:</p>
<ul>
<li><code>Service</code>: This is exposing the port to the ingress</li>
<li><code>Deployment</code>: This is actually launching the service</li>
</ul>
<p>So we are not using the ingress yet but we can prove that we can launch the
service at least.  So apply those manifests:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl apply -f httpbin.yml 
service/httpbin created
deployment.apps/httpbin created
</code></pre>
<p>You should see two pods come up.  You should wait for them to get into the
<code>Running</code> status:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl get pod -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
httpbin-5c5494967-2z5wz   1/1     Running   0          48s   10.244.3.3   kind-multinode-worker3   &#x3C;none>           &#x3C;none>
httpbin-5c5494967-9lf47   1/1     Running   0          72s   10.244.1.2   kind-multinode-worker    &#x3C;none>           &#x3C;none>
</code></pre>
<p>We can now use port forwarding to access it. <code>httpbin</code> is exposed on <code>8000</code> so
lets create port <code>9000</code> on our host that forwards to it:</p>
<pre><code class="hljs language-bash">‚ùØ kubectl port-forward service/httpbin 9000:8000
Forwarding from 127.0.0.1:9000 -> 80
Forwarding from [::1]:9000 -> 80
</code></pre>
<p>You can access it via:</p>
<pre><code class="hljs language-bash">‚ùØ curl localhost:9000/get 
{
  <span class="hljs-string">"args"</span>: {},
  <span class="hljs-string">"headers"</span>: {
    <span class="hljs-string">"Accept"</span>: [
      <span class="hljs-string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8"</span>
    ],
}
</code></pre>
<h1>Using Ingress</h1>
<p>Now to use the ingress rather than port forwarding we create one additional
resource, the <code>Ingress</code>:</p>
<pre><code class="hljs language-yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin-ingress</span>
  <span class="hljs-attr">annotations:</span>
    <span class="hljs-attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="hljs-string">/$2</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">ingressClassName:</span> <span class="hljs-string">nginx</span>
  <span class="hljs-attr">rules:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">http:</span>
      <span class="hljs-attr">paths:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">path:</span> <span class="hljs-string">/httpbin(/|$)(.*)</span>
        <span class="hljs-attr">pathType:</span> <span class="hljs-string">ImplementationSpecific</span>
        <span class="hljs-attr">backend:</span>
          <span class="hljs-attr">service:</span>
            <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin</span>
            <span class="hljs-attr">port:</span>
              <span class="hljs-attr">number:</span> <span class="hljs-number">8000</span>
</code></pre>
<p>There are a few critical options here.  The first is the annotation to rewrite
the path so it doesn't include <code>/httpbin/</code> when it sends the request to the
service and then the <code>path</code> and <code>pathType</code> so it knows which paths to send to
which service.</p>
<p>Now you should be able to hit your local host and get routed to your
kubernetes service:</p>
<pre><code class="hljs language-bash">‚ùØ curl localhost/httpbin/get
</code></pre>
<p>Success!  Now you have a multinode kubernetes cluster that has an ingress
controller!</p>
<h1>Next Steps</h1>
<p>The cluster can be used like a production cluster now for local
development!  You could setup Grafana, ArgoCD, etc. to run
inside the cluster.</p></div></article></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":["2023","local_k8s_with_kind"],"path":"2023/local_k8s_with_kind","contentHtml":"\u003cp\u003ePreviously I \u003ca href=\"/blog/2022/local_kubeadm_cluster\"\u003eshowed\u003c/a\u003e how to run kubernetes\nlocally with \u003ccode\u003ekubeadm\u003c/code\u003e and VMs but sometimes that is overkill so I wanted to\nshow how to run \u003ca href=\"https://kind.sigs.k8s.io/\"\u003ekind\u003c/a\u003e which is \"kuberetes in\ndocker\".\u003c/p\u003e\n\u003ch1\u003eCreating your first cluster\u003c/h1\u003e\n\u003cp\u003ekind is a very flexible way to run kubernetes locally and allows you to run\nsingle node or multinode clusters while having the flexibility to use all\nthe features of kubernetes success as ingress.\u003c/p\u003e\n\u003cp\u003eTo create your first cluster it is as simple as running:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kind create cluster  \n\nCreating cluster \u003cspan class=\"hljs-string\"\u003e\"kind\"\u003c/span\u003e ...\n ‚úì Ensuring node image (kindest/node:v1.27.3) üñº \n ‚úì Preparing nodes üì¶  \n ‚úì Writing configuration üìú \n ‚úì Starting control-plane üïπÔ∏è \n ‚úì Installing CNI üîå \n ‚úì Installing StorageClass üíæ \nSet kubectl context to \u003cspan class=\"hljs-string\"\u003e\"kind-kind\"\u003c/span\u003e\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kind\n\nHave a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/\u003cspan class=\"hljs-comment\"\u003e#community üôÇ\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou now have a functioning kubernetes cluster and you\ncan view what it created:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ k get node\nNAME                 STATUS   ROLES           AGE     VERSION\nkind-control-plane   Ready    control-plane   4m26s   v1.27.3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can also verify that it is running inside docker:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ docker ps\nCONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS         PORTS                       NAMES\n1c3ba74dc29b   kindest/node:v1.27.3   \u003cspan class=\"hljs-string\"\u003e\"/usr/local/bin/entr‚Ä¶\"\u003c/span\u003e   3 minutes ago   Up 3 minutes   127.0.0.1:59327-\u003e6443/tcp   kind-control-plane\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eMaking the cluster useful\u003c/h1\u003e\n\u003cp\u003eThere are a few things you'll notice with the command we ran originally:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt grabbed the latest kubernetes version available\u003c/li\u003e\n\u003cli\u003eIt is running a single node cluster\u003c/li\u003e\n\u003cli\u003eNo ingress available\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLuckily kind makes it really easy to customize your local cluster to be what\nyou want it to be by using a \u003ccode\u003eYAML\u003c/code\u003e configuration.\u003c/p\u003e\n\u003cp\u003eCreate the configuration:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e\u003cspan class=\"hljs-attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eCluster\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ekind.x-k8s.io/v1alpha4\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003enodes:\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003erole:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003econtrol-plane\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ekubeadmConfigPatches:\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e|\n    kind: InitConfiguration\n    nodeRegistration:\n      kubeletExtraArgs:\n        node-labels: \"ingress-ready=true\"\n\u003c/span\u003e  \u003cspan class=\"hljs-attr\"\u003eextraPortMappings:\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003econtainerPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e80\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003ehostPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e80\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eprotocol:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eTCP\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003econtainerPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e443\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003ehostPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e443\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eprotocol:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eTCP\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003erole:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eworker\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003erole:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eworker\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003erole:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eworker\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith this we've now generated a 4 node cluster where we have a single\ncontrol-plane and three workers.  Then we defined some extra configuration on\nthe control-plane:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ekubeadmConfigPatches\u003c/strong\u003e: We want to change the default configuration the\ncluster uses so it'll tag the nodes with the \u003ccode\u003eingress-ready\u003c/code\u003e label so the\ncontroller will use them.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eextraPortMappings\u003c/strong\u003e: allow the local host to make requests to the Ingress controller over ports 80/443\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003enode-labels\u003c/strong\u003e: only allow the ingress controller to run on specific node(s) matching the label selector\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo now we can create the new cluster with the configuration. Save that config\nas \u003ccode\u003ekind_config.yml\u003c/code\u003e and then run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kind create cluster --image kindest/node:v1.25.11 --config kind_config.yml --name kind-multinode\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis time I've added a few additional flags on the commandline. \u003ccode\u003e--image\u003c/code\u003e\nallows us to use a different version of kubernetes and \u003ccode\u003e--name\u003c/code\u003e allows us to\nmake more than one cluster. So if you didn't destroy the first cluster you'll\nsee we have two of them now:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kind get clusters\nkind\nkind-multinode\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebut \u003ccode\u003ekind\u003c/code\u003e will swap the to the newest cluster by default:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl config current-context\nkind-kind-multinode\n\n‚ùØ kubectl get node\nNAME                           STATUS   ROLES           AGE    VERSION\nkind-multinode-control-plane   Ready    control-plane   107s   v1.25.11\nkind-multinode-worker          Ready    \u0026#x3C;none\u003e          88s    v1.25.11\nkind-multinode-worker2         Ready    \u0026#x3C;none\u003e          88s    v1.25.11\nkind-multinode-worker3         Ready    \u0026#x3C;none\u003e          88s    v1.25.11\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we need to get the \u003ccode\u003eingress-nginx\u003c/code\u003e controller installed so we can start\nusing our cluster with ingress:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe manifests contains \u003ccode\u003ekind\u003c/code\u003e specific patches to forward the hostPorts to the ingress controller, set taint tolerations and schedule it to the custom labelled node.\u003c/p\u003e\n\u003cp\u003eThis will take a little bit of time to get up and running, you can monitor it\nby running:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003ekubectl \u003cspan class=\"hljs-built_in\"\u003ewait\u003c/span\u003e --namespace ingress-nginx \\\n  --\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e=condition=ready pod \\\n  --selector=app.kubernetes.io/component=controller \\\n  --\u003cspan class=\"hljs-built_in\"\u003etimeout\u003c/span\u003e=90s\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor just manually check the status:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl get all -n ingress-nginx\nNAME                                            READY   STATUS              RESTARTS   AGE\npod/ingress-nginx-admission-create-bbmlc        0/1     Completed           0          68s\npod/ingress-nginx-admission-patch-qlnr8         0/1     Completed           2          68s\npod/ingress-nginx-controller-5f748f78c8-6tc6b   0/1     ContainerCreating   0          68s\n\nNAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nservice/ingress-nginx-controller             NodePort    10.96.228.248   \u0026#x3C;none\u003e        80:31771/TCP,443:31759/TCP   68s\nservice/ingress-nginx-controller-admission   ClusterIP   10.96.180.126   \u0026#x3C;none\u003e        443/TCP                      68s\n\nNAME                                       READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/ingress-nginx-controller   0/1     1            0           68s\n\nNAME                                                  DESIRED   CURRENT   READY   AGE\nreplicaset.apps/ingress-nginx-controller-5f748f78c8   1         1         0       68s\n\nNAME                                       COMPLETIONS   DURATION   AGE\njob.batch/ingress-nginx-admission-create   1/1           22s        68s\njob.batch/ingress-nginx-admission-patch    1/1           35s        68s\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce \u003ccode\u003eingress-nginx-controller\u003c/code\u003e is in \u003ccode\u003eRunning\u003c/code\u003e state you are read to go!\u003c/p\u003e\n\u003ch1\u003eDeploying your first app\u003c/h1\u003e\n\u003cp\u003eTo prove that the cluster is working correctly we will deploy\n\u003ca href=\"https://github.com/Kong/httpbin\"\u003ehttpbin\u003c/a\u003e which is a nice little API server\nso we can prove everything is working.\u003c/p\u003e\n\u003cp\u003eCreate a \u003ccode\u003ehttbin.yml\u003c/code\u003e file and paste this into it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e\u003cspan class=\"hljs-meta\"\u003e---\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ev1\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eService\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003emetadata:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003elabels:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eapp:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eservice:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003eports:\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttp\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eport:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8000\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003etargetPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8080\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003eselector:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003eapp:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n\u003cspan class=\"hljs-meta\"\u003e---\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eapps/v1\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eDeployment\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003emetadata:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ereplicas:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003eselector:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003ematchLabels:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eapp:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003eversion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ev1\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003etemplate:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003emetadata:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003elabels:\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eapp:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eversion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ev1\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003econtainers:\u003c/span\u003e\n      \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eimage:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003edocker.io/mccutchen/go-httpbin\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eimagePullPolicy:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eIfNotPresent\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003eports:\u003c/span\u003e\n        \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003econtainerPort:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8080\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is creating a couple of Kubernetes resources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eService\u003c/code\u003e: This is exposing the port to the ingress\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDeployment\u003c/code\u003e: This is actually launching the service\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo we are not using the ingress yet but we can prove that we can launch the\nservice at least.  So apply those manifests:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl apply -f httpbin.yml \nservice/httpbin created\ndeployment.apps/httpbin created\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see two pods come up.  You should wait for them to get into the\n\u003ccode\u003eRunning\u003c/code\u003e status:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl get pod -o wide\nNAME                      READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES\nhttpbin-5c5494967-2z5wz   1/1     Running   0          48s   10.244.3.3   kind-multinode-worker3   \u0026#x3C;none\u003e           \u0026#x3C;none\u003e\nhttpbin-5c5494967-9lf47   1/1     Running   0          72s   10.244.1.2   kind-multinode-worker    \u0026#x3C;none\u003e           \u0026#x3C;none\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can now use port forwarding to access it. \u003ccode\u003ehttpbin\u003c/code\u003e is exposed on \u003ccode\u003e8000\u003c/code\u003e so\nlets create port \u003ccode\u003e9000\u003c/code\u003e on our host that forwards to it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ kubectl port-forward service/httpbin 9000:8000\nForwarding from 127.0.0.1:9000 -\u003e 80\nForwarding from [::1]:9000 -\u003e 80\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can access it via:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ curl localhost:9000/get \n{\n  \u003cspan class=\"hljs-string\"\u003e\"args\"\u003c/span\u003e: {},\n  \u003cspan class=\"hljs-string\"\u003e\"headers\"\u003c/span\u003e: {\n    \u003cspan class=\"hljs-string\"\u003e\"Accept\"\u003c/span\u003e: [\n      \u003cspan class=\"hljs-string\"\u003e\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\"\u003c/span\u003e\n    ],\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eUsing Ingress\u003c/h1\u003e\n\u003cp\u003eNow to use the ingress rather than port forwarding we create one additional\nresource, the \u003ccode\u003eIngress\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-yaml\"\u003e\u003cspan class=\"hljs-attr\"\u003eapiVersion:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003enetworking.k8s.io/v1\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003ekind:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eIngress\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003emetadata:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin-ingress\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003eannotations:\u003c/span\u003e\n    \u003cspan class=\"hljs-attr\"\u003enginx.ingress.kubernetes.io/rewrite-target:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e/$2\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003espec:\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003eingressClassName:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003enginx\u003c/span\u003e\n  \u003cspan class=\"hljs-attr\"\u003erules:\u003c/span\u003e\n  \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ehttp:\u003c/span\u003e\n      \u003cspan class=\"hljs-attr\"\u003epaths:\u003c/span\u003e\n      \u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003epath:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e/httpbin(/|$)(.*)\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003epathType:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eImplementationSpecific\u003c/span\u003e\n        \u003cspan class=\"hljs-attr\"\u003ebackend:\u003c/span\u003e\n          \u003cspan class=\"hljs-attr\"\u003eservice:\u003c/span\u003e\n            \u003cspan class=\"hljs-attr\"\u003ename:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ehttpbin\u003c/span\u003e\n            \u003cspan class=\"hljs-attr\"\u003eport:\u003c/span\u003e\n              \u003cspan class=\"hljs-attr\"\u003enumber:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e8000\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThere are a few critical options here.  The first is the annotation to rewrite\nthe path so it doesn't include \u003ccode\u003e/httpbin/\u003c/code\u003e when it sends the request to the\nservice and then the \u003ccode\u003epath\u003c/code\u003e and \u003ccode\u003epathType\u003c/code\u003e so it knows which paths to send to\nwhich service.\u003c/p\u003e\n\u003cp\u003eNow you should be able to hit your local host and get routed to your\nkubernetes service:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e‚ùØ curl localhost/httpbin/get\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSuccess!  Now you have a multinode kubernetes cluster that has an ingress\ncontroller!\u003c/p\u003e\n\u003ch1\u003eNext Steps\u003c/h1\u003e\n\u003cp\u003eThe cluster can be used like a production cluster now for local\ndevelopment!  You could setup Grafana, ArgoCD, etc. to run\ninside the cluster.\u003c/p\u003e","category":"Kubernetes","date":"2023-07-20T20:00:00-04:00","tags":["Linux","Kubernetes","DevOps","SRE"],"title":"Running a kubernetes cluster locally with kind"}},"__N_SSG":true},"page":"/blog/[...id]","query":{"id":["2023","local_k8s_with_kind"]},"buildId":"yFdG3iKkjvLWIOVsrJ3da","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>