{"pageProps":{"postData":{"id":["2022","learning_spanish"],"path":"2022/learning_spanish","contentHtml":"<p>I've been living in Puerto Rico for 4 years but two of those have been COVID and so I haven't been able to practice Spanish as much as I'd like. So to speed up my learning I've decided I want to watch a lot of spanish speaking television to start training my ears, but to do this I need a baseline of words I understand to be able to even know what they are saying!</p>\n<p>Learning through apps like Duolingo, Drops, etc start with weird topics like vegetables that don't get you to a very good baseline for actually understanding daily conversations, so I think consuming TV is a better use of my time.</p>\n<h2>Subtitles</h2>\n<p>I've decided the way to understand what the best words to study are is to download every subtitle for every episode of a show I want to watch and then count each word.  The more a word is spoken the more important it is for me to know it since I'll be hearing it a lot in the show.</p>\n<p>I'm going to download subtitles from Netflix. Subtitles in Netflix are in WebVTT format, which looks like this:</p>\n<pre><code class=\"hljs language-arduino\"><span class=\"hljs-number\">248</span>\n<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">17</span>:<span class=\"hljs-number\">58.285</span> --> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span>:<span class=\"hljs-number\">01.163</span>  position:<span class=\"hljs-number\">50.00</span>%,middle  align:middle size:<span class=\"hljs-number\">80.00</span>%  line:<span class=\"hljs-number\">79.33</span>% \nYo de verdad espero que ustedes\nme vean como una amiga, ¿mmm?\n\n<span class=\"hljs-number\">249</span>\n<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span>:<span class=\"hljs-number\">01.247</span> --> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span>:<span class=\"hljs-number\">02.539</span>  position:<span class=\"hljs-number\">50.00</span>%,middle  align:middle size:<span class=\"hljs-number\">80.00</span>%  line:<span class=\"hljs-number\">84.67</span>% \nNo como una madrastra.\n\n<span class=\"hljs-number\">250</span>\n<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span>:<span class=\"hljs-number\">04.250</span> --> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span>:<span class=\"hljs-number\">06.127</span>  position:<span class=\"hljs-number\">50.00</span>%,middle  align:middle size:<span class=\"hljs-number\">80.00</span>%  line:<span class=\"hljs-number\">84.67</span>% \nYo nunca te vi como una madrastra.\n</code></pre>\n<p>It gives you a start time, end time, and the text on the screen.   So my first process was parsing this format and just turning it into a list of words using https://github.com/glut23/webvtt-py.</p>\n<h3>Dummy parsing</h3>\n<p>What I basically did was <code>text.split(\" \")</code> and started counting the words.   This approach was quick and painless but it had a few downs falls.    Some words <em>look</em> the same when in reality they are not and so this meant I'd have to study every meaning of a word even if it was more rare.</p>\n<p>An example of this is the word \"como\", you can say:</p>\n<ul>\n<li>Haz como te digo: \"Do as I say\", where como means \"as\"</li>\n<li>como tacos todos los dias: \"I eat tacos every day\", where como is a conjugated form of the verb \"to eat\"</li>\n</ul>\n<p>I need to know which version of a word is being used so I can count it properly.</p>\n<h3>Regular Expressions are always the answer</h3>\n<p>I couldn't figure out what the word was without it being in a complete sentence, but subtitles are fragments.   They are split up into timings for displaying on the screen but they don't include entire sentences.  For example, it might look like this:</p>\n<pre><code class=\"hljs language-arduino\"><span class=\"hljs-number\">23</span>\n<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">21.960</span> --> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">23.520</span>  position:<span class=\"hljs-number\">50.00</span>%,middle  align:middle size:<span class=\"hljs-number\">80.00</span>%  line:<span class=\"hljs-number\">84.67</span>% \nSolo las que luchan por ellos\n\n<span class=\"hljs-number\">24</span>\n<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">23.680</span> --> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">25.680</span>  position:<span class=\"hljs-number\">50.00</span>%,middle  align:middle size:<span class=\"hljs-number\">80.00</span>%  line:<span class=\"hljs-number\">84.67</span>% \nconsiguen sus sueños.\n</code></pre>\n<p>I want to detect the start of a sentence and the end of a sentence and then combine it, so that you end up with \"Solo las que luchan por ellos consiguen sus sueños.\".   My first thought was a regular expression on punctuation.   This worked well <em>most</em> of the time but there were enough exceptions to the rule that it broke often on generated a lot of broken sentences:</p>\n<ul>\n<li>Abbreviations like \"EE. UU\" for estados unidos (united states)</li>\n<li>Ellipsis</li>\n</ul>\n<p>Splitting on spaces also didn't work for identifying the parts of speech since I needed the context around the word.</p>\n<center>\n<img src=\"/images/posts/learning_spanish/regex-extraction.png\">\n</center>\n<h2>Natural Language Processing</h2>\n<p>So to solve my pain I decided to grab https://spacy.io/ and do some NLP on the subtitles so that I could identify the proper parts of speech and get an accurate representation of the words I needed to learn.</p>\n<p>The way spaCy works is you can send it a sentence and it'll return you a set of tokens:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-meta\">>>> </span><span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-meta\">>>> </span>nlp = spacy.load(<span class=\"hljs-string\">\"es_core_news_sm\"</span>)\n<span class=\"hljs-meta\">>>> </span>[x.pos_ <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> nlp(<span class=\"hljs-string\">\"Hola, como estas?\"</span>)]\n[<span class=\"hljs-string\">'PROPN'</span>, <span class=\"hljs-string\">'PUNCT'</span>, <span class=\"hljs-string\">'SCONJ'</span>, <span class=\"hljs-string\">'PRON'</span>, <span class=\"hljs-string\">'PUNCT'</span>]\n</code></pre>\n<p>So now I could identify the parts of speech and pull sentences together through end of sentence punctation.   The first thing I did was generate a CSV of sentences that looked like this:</p>\n<table>\n<tbody><tr>\n<th>sentence</th>\n<th>start</th>\n<th>end</th>\n<th>show</th>\n<th>file</th>\n</tr>\n<tr>\n<td>Si no, le voy a cortar todos los deditos</td>\n<td>00:00:20.605</td>\n<td>00:00:24.125</td>\n<td>El marginal</td>\n<td>El marginal S02E02 WEBRip Netflix es[cc].vtt</td>\n</tr>\n</tbody></table>\n<p>Once I had a CSV of sentences I could send those back through spaCy for NLP and then start counting words, to generate another CSV:</p>\n<table>\n<tbody><tr>\n<th>word</th>\n<th>pos</th>\n<th>show</th>\n<th>file</th>\n</tr>\n<tr>\n<td>a</td>\n<td>ADP</td>\n<td>El marginal</td>\n<td>El marginal S02E02 WEBRip Netflix es[cc].vtt</td>\n</tr>\n<tr>\n<td>cortar</td>\n<td>VERB</td>\n<td>El marginal</td>\n<td>El marginal S02E02 WEBRip Netflix es[cc].vtt</td>\n</tr>\n<tr>\n<td>todos</td>\n<td>PRON</td>\n<td>El marginal</td>\n<td>El marginal S02E02 WEBRip Netflix es[cc].vtt</td>\n</tr>\n</tbody></table>\n<p>From there I had all the data I needed!   So now it was time to start doing some data analysis!</p>\n<h2>Data analysis</h2>\n<p>Using a jupyter notebook ( https://jupyter.org/ ) I grabbed pandas ( https://pandas.pydata.org/ ) and read in my CSVs to start analyzing the results.</p>\n<pre><code class=\"hljs language-javascript\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> matplotlib.<span class=\"hljs-property\">pyplot</span> <span class=\"hljs-keyword\">as</span> plt\npd.<span class=\"hljs-title function_\">set_option</span>(<span class=\"hljs-string\">'display.max_rows'</span>, <span class=\"hljs-number\">1000</span>)\nwords = pd.<span class=\"hljs-title function_\">read_csv</span>(<span class=\"hljs-string\">'word_data.csv.gz'</span>, compression=<span class=\"hljs-string\">'gzip'</span>, delimiter=<span class=\"hljs-string\">','</span>)\n</code></pre>\n<p>The words dataframe is built up out of the second table I showed above with just words and their parts of speech.   I started off grouping the dataset by the word so I could get a count for how many times it was spoken in every series I parsed:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">grouped_result</span> = (words.groupby(words.word).size() \n   .sort_values(<span class=\"hljs-attr\">ascending</span>=<span class=\"hljs-literal\">False</span>) \n   .reset_index(<span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">'count'</span>)\n   .drop_duplicates(<span class=\"hljs-attr\">subset</span>=<span class=\"hljs-string\">'word'</span>))\n\ngrouped_result.head(300)\n</code></pre>\n<p>Which returned a list of words and their count:</p>\n<pre><code class=\"hljs language-arduino\">\t<span class=\"hljs-type\">word</span>\tcount\n<span class=\"hljs-number\">0</span>\tque\t<span class=\"hljs-number\">94430</span>\n<span class=\"hljs-number\">1</span>\tno\t<span class=\"hljs-number\">75931</span>\n<span class=\"hljs-number\">2</span>\ta\t<span class=\"hljs-number\">70968</span>\n<span class=\"hljs-number\">3</span>\tde\t<span class=\"hljs-number\">67982</span>\n<span class=\"hljs-number\">4</span>\tser\t<span class=\"hljs-number\">64226</span>\n<span class=\"hljs-number\">5</span>\tla\t<span class=\"hljs-number\">52143</span>\n<span class=\"hljs-number\">6</span>\ty\t<span class=\"hljs-number\">44390</span>\n<span class=\"hljs-number\">7</span>\testar\t<span class=\"hljs-number\">37819</span>\n<span class=\"hljs-number\">8</span>\tel\t<span class=\"hljs-number\">35920</span>\n</code></pre>\n<p>Now I wanted to identify where my diminishing returns would be.   Is there a set of words that I must learn because they are spoken so often that I wouldn't understand a conversation if they weren't in my vocabulary?</p>\n<center>\n<img src=\"/images/posts/learning_spanish/diminishing_returns.png\">\n</center>\n<p>As you can see in this chart, the usage for words drops off at around the ~200 mark.   So there are basically 150 words I <em>must</em> know and then the rest are equally important.   I wasn't quite happy with this because some parts of speech are higher priority than others, for example I think having a strong understanding of the popular verbs will go a long way.  So I also wanted to identify what are the most important verbs to learn:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">grouped_verbs</span> = (words[words.pos == <span class=\"hljs-string\">'VERB'</span>].groupby([<span class=\"hljs-string\">'word'</span>, <span class=\"hljs-string\">'pos'</span>]).size() \n   .sort_values(<span class=\"hljs-attr\">ascending</span>=<span class=\"hljs-literal\">False</span>) \n   .reset_index(<span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">'count'</span>)\n   .drop_duplicates(<span class=\"hljs-attr\">subset</span>=<span class=\"hljs-string\">'word'</span>))\n\ngrouped_verbs.head(50)\n</code></pre>\n<p>Which got me this:</p>\n<pre><code class=\"hljs language-yaml\">\t<span class=\"hljs-string\">word</span>\t<span class=\"hljs-string\">pos</span>\t<span class=\"hljs-string\">count</span>\n<span class=\"hljs-number\">0</span>\t<span class=\"hljs-string\">tener</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">22072</span>\n<span class=\"hljs-number\">1</span>\t<span class=\"hljs-string\">hacer</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">14946</span>\n<span class=\"hljs-number\">2</span>\t<span class=\"hljs-string\">ir</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">12570</span>\n<span class=\"hljs-number\">3</span>\t<span class=\"hljs-string\">decir</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">11314</span>\n<span class=\"hljs-number\">4</span>\t<span class=\"hljs-string\">querer</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">11083</span>\n<span class=\"hljs-number\">5</span>\t<span class=\"hljs-string\">ver</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">10269</span>\n<span class=\"hljs-number\">6</span>\t<span class=\"hljs-string\">estar</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">9780</span>\n<span class=\"hljs-number\">7</span>\t<span class=\"hljs-string\">saber</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">8704</span>\n<span class=\"hljs-number\">8</span>\t<span class=\"hljs-string\">ser</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">7674</span>\n<span class=\"hljs-number\">9</span>\t<span class=\"hljs-string\">dar</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">5722</span>\n<span class=\"hljs-number\">10</span>\t<span class=\"hljs-string\">pasar</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">5528</span>\n<span class=\"hljs-number\">11</span>\t<span class=\"hljs-string\">hablar</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">5355</span>\n<span class=\"hljs-number\">12</span>\t<span class=\"hljs-string\">venir</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">5145</span>\n<span class=\"hljs-number\">13</span>\t<span class=\"hljs-string\">creer</span>\t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">4895</span>\n<span class=\"hljs-number\">14</span>\t<span class=\"hljs-string\">salir</span> \t<span class=\"hljs-string\">VERB</span>\t<span class=\"hljs-number\">3395</span>\n</code></pre>\n<p>Verbs had a slightly different drop-off pattern when I targeted them directly:</p>\n<center>\n<img src=\"/images/posts/learning_spanish/diminishing_verbs.png\">\n</center>\n<p>I get a big bang for my buck by learning those top 40 verbs.   Nouns on the other hand are much more spread out and most are evenly distributed:</p>\n<pre><code class=\"hljs language-yaml\"><span class=\"hljs-string\">word</span>\t<span class=\"hljs-string\">pos</span>\t<span class=\"hljs-string\">count</span>\n<span class=\"hljs-number\">0</span>\t<span class=\"hljs-string\">gracias</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">4676</span>\n<span class=\"hljs-number\">1</span>\t<span class=\"hljs-string\">favor</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">4625</span>\n<span class=\"hljs-number\">2</span>\t<span class=\"hljs-string\">señor</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">4116</span>\n<span class=\"hljs-number\">3</span>\t<span class=\"hljs-string\">verdad</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">3566</span>\n<span class=\"hljs-number\">4</span>\t<span class=\"hljs-string\">vida</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2673</span>\n<span class=\"hljs-number\">5</span>\t<span class=\"hljs-string\">hombre</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2601</span>\n<span class=\"hljs-number\">6</span>\t<span class=\"hljs-string\">madre</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2597</span>\n<span class=\"hljs-number\">7</span>\t<span class=\"hljs-string\">vez</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2537</span>\n<span class=\"hljs-number\">8</span>\t<span class=\"hljs-string\">tiempo</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2492</span>\n<span class=\"hljs-number\">9</span>\t<span class=\"hljs-string\">hijo</span>\t<span class=\"hljs-string\">NOUN</span>\t<span class=\"hljs-number\">2215</span>\n</code></pre>\n<center>\n<img src=\"/images/posts/learning_spanish/diminishing_nouns.png\">\n</center>\n<p>So then I thought to myself... How much of a show would I understand if I just learned these most important words?  So I started by excluding some of the easy parts of speech and focused on the most important:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">find_important_words</span> = (words[~words.pos.isin([<span class=\"hljs-string\">'PRON'</span>, <span class=\"hljs-string\">'CONJ'</span>, <span class=\"hljs-string\">'ADP'</span>, <span class=\"hljs-string\">'ADV'</span>, <span class=\"hljs-string\">'SCONJ'</span>, <span class=\"hljs-string\">'AUX'</span>, <span class=\"hljs-string\">'INTJ'</span>])].groupby([<span class=\"hljs-string\">'word'</span>, <span class=\"hljs-string\">'pos'</span>]).size() \n   .sort_values(<span class=\"hljs-attr\">ascending</span>=<span class=\"hljs-literal\">False</span>) \n   .reset_index(<span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">'count'</span>)\n   .drop_duplicates(<span class=\"hljs-attr\">subset</span>=<span class=\"hljs-string\">'word'</span>))\n\nfind_important_words.head(50)\n</code></pre>\n<p>The top 20 were all verbs except for <code>bueno</code> and <code>gracias</code>.   So now with my list of what I considered \"important words\" I plotted it to find what amount of words I wanted to learn:</p>\n<center>\n<img src=\"/images/posts/learning_spanish/important_words.png\">\n</center>\n<p>It looks like 200 learned words would give me a reasonable amount of understanding for a series, so I decided to calculate how much of a series I would understand if I learned just those first 200 words:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">percentages</span> = {}\n\nfor show_name in words<span class=\"hljs-section\">['media']</span>.drop_duplicates().values:\n    <span class=\"hljs-attr\">words_in_show</span> = (words[words.media == show_name].groupby(words.word).size() \n       .sort_values(<span class=\"hljs-attr\">ascending</span>=<span class=\"hljs-literal\">False</span>) \n       .reset_index(<span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">'count'</span>)\n       .drop_duplicates(<span class=\"hljs-attr\">subset</span>=<span class=\"hljs-string\">'word'</span>))\n    \n    <span class=\"hljs-attr\">total_words_handled</span> = <span class=\"hljs-number\">0</span>\n\n    for word in grouped_result<span class=\"hljs-section\">['word']</span><span class=\"hljs-section\">[:200]</span>:\n        <span class=\"hljs-attr\">values</span> = words_in_show[words_in_show.word == word][<span class=\"hljs-string\">'count'</span>].values\n\n        if values.size > 0:\n            total_words_handled += values<span class=\"hljs-section\">[0]</span>\n\n    percentages<span class=\"hljs-section\">[show_name]</span> = total_words_handled / words_in_show.sum().loc<span class=\"hljs-section\">['count']</span>\n</code></pre>\n<p>Now I had a table that would show me what percentage of the spoken words were covered by the first 200 words in my list:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">p_df</span> = pd.DataFrame(percentages.items(), columns=[<span class=\"hljs-string\">'show'</span>, <span class=\"hljs-string\">'percentage'</span>])\n<span class=\"hljs-attr\">p_df</span> = p_df.sort_values(by=<span class=\"hljs-string\">'percentage'</span>)\np_df<span class=\"hljs-section\">['percentage']</span> = p_df<span class=\"hljs-section\">['percentage']</span> * 100\n<span class=\"hljs-attr\">pd.options.display.float_format</span> = <span class=\"hljs-string\">'{:,.2f}%'</span>.format\np_df\n</code></pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table>\n<tbody><tr>\n<th>Show</th>\n<th>Percentage</th>\n</tr><tr>\n<td>Verónica</td>\n<td>64.24%</td>\n</tr><tr>\n<td>El ciudadano ilustre</td>\n<td>65.28%</td>\n</tr><tr>\n<td>El Chapo</td>\n<td>66.68%</td>\n</tr><tr>\n<td>Neruda</td>\n<td>66.89%</td>\n</tr><tr>\n<td>La casa de papel</td>\n<td>67.56%</td>\n</tr><tr>\n<td>El Ministerio del Tiempo</td>\n<td>68.03%</td>\n</tr><tr>\n<td>Club de Cuervos</td>\n<td>68.19%</td>\n</tr><tr>\n<td>El marginal</td>\n<td>68.47%</td>\n</tr><tr>\n<td>Ingobernable</td>\n<td>68.59%</td>\n</tr><tr>\n<td>Pablo Escobar</td>\n<td>70.20%</td>\n</tr><tr>\n<td>Fariña</td>\n<td>70.95</td>\n</tr><tr>\n<td>La Reina del Sur</td>\n<td>71.52%</td>\n</tr><tr>\n<td>Gran Hotel</td>\n<td>73.15%</td>\n</tr><tr>\n<td>Las chicas del cable</td>\n<td>73.58%</td>\n</tr><tr>\n<td>Élite</td>\n<td>73.78%</td>\n</tr><tr>\n<td>La Piloto</td>\n<td>74.03%</td>\n</tr><tr>\n<td>El bar</td>\n<td>74.07%</td>\n</tr><tr>\n<td>La casa de las flores</td>\n<td>75.40%</td>\n</tr><tr>\n<td>Tarde para la ira</td>\n<td>75.59%</td>\n</tr></tbody></table>\n<p>But living in Puerto Rico, one thing I've realized is speed of speech is also important.  I have a much easier time speaking with people from Colombia and Mexico than I do with Puerto Ricans because they speak so much faster.   So even though I could understand 75% of \"Tarde para la ira\" if I learned the 200 words, I want to make sure they are speaking at a pace I could understand as well.</p>\n<p>So I loaded up the other CSV file that was the full sentences and added a \"time per word\" column:</p>\n<pre><code class=\"hljs language-css\">sentences = pd<span class=\"hljs-selector-class\">.read_csv</span>('sentences<span class=\"hljs-selector-class\">.csv</span><span class=\"hljs-selector-class\">.gz</span>', compression='gzip', delimiter=',', parse_dates=<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'start'</span>, <span class=\"hljs-string\">'end'</span>]</span>)\nsentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'total_time'</span>]</span> = (sentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'end'</span>]</span> - sentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'start'</span>]</span>)<span class=\"hljs-selector-class\">.dt</span><span class=\"hljs-selector-class\">.total_seconds</span>()\nsentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'word_count'</span>]</span> = sentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'sentence'</span>]</span><span class=\"hljs-selector-class\">.str</span><span class=\"hljs-selector-class\">.split</span>()<span class=\"hljs-selector-class\">.str</span><span class=\"hljs-selector-class\">.len</span>()\nsentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'time_per_word'</span>]</span> = sentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'total_time'</span>]</span> / sentences<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'word_count'</span>]</span>\n</code></pre>\n<p>Then I was able to have a speed rating for each show:</p>\n<pre><code class=\"hljs language-scss\">sentence_group = sentences<span class=\"hljs-selector-class\">.groupby</span>([sentences.media])\nsentence_group<span class=\"hljs-selector-class\">.time_per_word</span><span class=\"hljs-selector-class\">.mean</span>()<span class=\"hljs-selector-class\">.reset_index</span>()<span class=\"hljs-selector-class\">.sort_values</span>('time_per_word')\n</code></pre>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table>\n<tbody><tr>\n<th>media</th>\n<th>time_per_word</th>\n</tr><tr>\n<td>Gran Hotel</td>\n<td>0.58</td>\n</tr><tr>\n<td>El Chapo</td>\n<td>0.59</td>\n</tr><tr>\n<td>Las chicas del cable</td>\n<td>0.61</td>\n</tr><tr>\n<td>Élite</td>\n<td>0.63</td>\n</tr><tr>\n<td>Ingobernable</td>\n<td>0.64</td>\n</tr><tr>\n<td>El Ministerio del Tiempo</td>\n<td>0.64</td>\n</tr><tr>\n<td>Fariña</td>\n<td>0.65</td>\n</tr><tr>\n<td>El ciudadano ilustre</td>\n<td>0.67</td>\n</tr><tr>\n<td>Neruda</td>\n<td>0.68</td>\n</tr><tr>\n<td>La Piloto</td>\n<td>0.69</td>\n</tr><tr>\n<td>La casa de papel</td>\n<td>0.70</td>\n</tr><tr>\n<td>El bar</td>\n<td>0.70</td>\n</tr><tr>\n<td>Verónica</td>\n<td>0.72</td>\n</tr><tr>\n<td>La Reina del Sur</td>\n<td>0.75</td>\n</tr><tr>\n<td>Club de Cuervos</td>\n<td>0.76</td>\n</tr><tr>\n<td>El marginal</td>\n<td>0.76</td>\n</tr><tr>\n<td>Pablo Escobar</td>\n<td>0.77</td>\n</tr><tr>\n<td>Tarde para la ira</td>\n<td>0.77</td>\n</tr><tr>\n<td>La casa de las flores</td>\n<td>0.81</td>\n</tr></tbody></table>\n<p>Luckily the two series that have the least amount of vocabulary also speak the slowest!   So these will be the series I start with.    The final question I wanted to answer is \"What are the top words I'm missing for a series\".    Since I'll know 75% of the series from the top 200 words, I'm hoping there are some top words from a specific series that I can also learn to get an even higher understanding.</p>\n<p>First, find which words are in each show but not in the top 200:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">missing_words_by_show</span> = {}\n\nfor show_name in words<span class=\"hljs-section\">['media']</span>.drop_duplicates().values:\n    <span class=\"hljs-attr\">words_in_show</span> = (words[words.media == show_name].groupby(words.word).size() \n       .sort_values(<span class=\"hljs-attr\">ascending</span>=<span class=\"hljs-literal\">False</span>) \n       .reset_index(<span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">'count'</span>)\n       .drop_duplicates(<span class=\"hljs-attr\">subset</span>=<span class=\"hljs-string\">'word'</span>))\n    \n    <span class=\"hljs-attr\">frequency_words</span> = grouped_result[<span class=\"hljs-string\">'word'</span>][:<span class=\"hljs-number\">200</span>]\n\n    <span class=\"hljs-attr\">missing_words</span> = words_in_show[~words_in_show.word.isin(frequency_words.values)]\n    missing_words_by_show<span class=\"hljs-section\">[show_name]</span> = missing_words\n</code></pre>\n<p>Then we were able to grab them per show:</p>\n<pre><code class=\"hljs language-css\">missing_words_by_show<span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'La casa de las flores'</span>]</span><span class=\"hljs-selector-class\">.head</span>(<span class=\"hljs-number\">50</span>)\n\nword\tcount\n<span class=\"hljs-number\">31</span>\tmamá\t<span class=\"hljs-number\">252</span>\n<span class=\"hljs-number\">70</span>\tflorerí<span class=\"hljs-selector-tag\">a</span>\t<span class=\"hljs-number\">87</span>\n<span class=\"hljs-number\">98</span>\tperdón\t<span class=\"hljs-number\">56</span>\n<span class=\"hljs-number\">102</span>\tsea\t<span class=\"hljs-number\">54</span>\n<span class=\"hljs-number\">116</span>\tademás\t<span class=\"hljs-number\">44</span>\n<span class=\"hljs-number\">126</span>\tahorita\t<span class=\"hljs-number\">40</span>\n<span class=\"hljs-number\">132</span>\tcárcel\t<span class=\"hljs-number\">38</span>\n<span class=\"hljs-number\">133</span>\tfiesta\t<span class=\"hljs-number\">38</span>\n</code></pre>\n<p>So adding those few words to my vocabulary will also give me a better understanding of the series.</p>\n<h2>Conclusion</h2>\n<p>I believe a data-driven approach to language learning will be an effective way to get me speaking better spanish.   It was a ton of fun to play with spaCy, pandas, and jupyter as well!</p>\n<p>I'll improve the data analysis over time as well but I do believe this is a pretty good starting point!</p>\n<center>\n<img src=\"/images/posts/learning_spanish/meme.png\">\n</center>","category":"development","date":"2022-04-30T00:00:00Z","tags":["pandas","nlp"],"title":"How to speak spanish like a colombian drug lord!"}},"__N_SSG":true}